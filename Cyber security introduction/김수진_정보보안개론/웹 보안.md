# 웹의 이해
<br>

- 1969년 미국 국방부 산하 고등연구계획국인 ARPA는 전 세계 주요 거점을 연결하는 네트워크인 알파넷을 만들었다.

- 1970년대에 네트워크는 TCP/IP 프로토콜로 연결되고 일반에 공개된에 따라 크게 발전하기 시작했다.

- 1994년 한국통신이 카이스트와 연구 기관 등에 학술 교육/정보 교류용으로 제공한 '하나망'을 일반에 개방하고 코넷을 시작했다.

- 1989년 스위스 제네바의 유럽입자물리연구소에서 근무하던 팀 버너스 리가 연구 목적의 프로젝트로 월드 와이드 웹을 시작했다

- 1960년대에 테드 넬슨이 '하이퍼텍스트 프로젝트'라는 신조어를 만들었다.

<BR>

# HTTP의 이해
<BR>

- HTTP는 가장 흔히 쓰이는 프로토콜이다.

- HTTP는 웹 처리 전반에 걸친 토대가 되기 때문에 웹 서버를 HTTP 서버라고 부르기도 한다.

<BR>

## HTTP 프로토콜
<BR>

- HTTP 0.9는 하나의 웹 페이지 안에서도 텍스트와 그림이 반복적으로 Connect 과정을 거쳐야 하는 등 매우 비효율적이었기 때문에 오래 사용되지 못했다.

- 1.1 버전부터는 한 번의 Connect 과정 후에 Request와 Response를 반복할 수 있게 됐다.

<br>

## HTTP Request
<br>

: 웹 서버에 데이터를 요청하거나 전송할 때 보내는 패킷이다.

<br>

### 1. GET 방식
<BR>

- 가장 일반적인 HTTP Request 형태이다.

- 요청 데이터의 인수를 웹 브라우저의 URL을 통해 전송한다.

- 보안에 매우 취약한 방식이므로 인증 관련 정보를 GET 방식으로 전당하면 안 된다.

<BR>

### 2. POST 방식
<BR>

- URL에 요청 데이터를 기록하지 않고 HTTP 헤더에 데이터를 전송한다.

- GET 방식에 비해 처리 속도가 상대적으로 느리다.

- POST 방식에서는 인수값을 URL을 통해 정송하지 않기 때문에 다른 사용자가 링크를 통해 해당 페이지를 볼 수 없다.

<BR>

### 3. 기타 방식
<BR>

> HEAD 방식
- 서버 측의 데이터를 검색하고 요청하는 데 사용된다.

<BR>

> POTIONS 방식
- 자원에 대한 요구/응답 관계에서 관련된 선택 사항의 정보를 요청할 때 사용된다.

<BR>

> PUT 방식
- 메세이제 포한되어 데이터를 지정한 URL 장소에 그 이름으로 저장한다.

<BR>

> DELETE 방식
- URL에 지정되어 있는 자원을 서버에서 지울 수 있게 한다.

<BR>

> TRACE 방식
- 요구 메세지의 최종 수신처까지 루프백을 검사하는 용도로 쓰인다.

<BR>

## HTTP Response
<br>

: 클라이언트의 HTTP Response에 대한 응답 패킷이다.

- Request에 대한 실행 결과 코드 및 간략한 실행 결과 설명문에 대한 내용이 담겨 있다.

<br>

# 웹 서비스의 이해
<br>

- 웹 서비스는 웹 언어를 통해 제공된다.

<br>

## HTML
<BR>

- 가장 단순한 형태의 웹 언어이다.

- 웹 서버에 HTML 문서를 저장하고 있다가 클라이언트가 특정 HTML 페이지를 요청하면 해당 문서를 클라이언트에 전송한다.

- 클라이언트는 웹 페이지를 해석하여 웹 브라우저에 표현해주는데, 이런 웹 페이지를 정적인 웹 페이지라고 한다.

<BR>

## SSS
<BR>

- 동적인 페이지를 제공하는 스크립트이다.

- 동적인 웹 페이지에서는 스크립트에 HTML 확장자 대신 ASP 또는 JSP 확장자를 가진 웹 문서를 요청한다.

<BR>

## CSS
<BR>

- 클라이언트 측의 웹 브라우저에 의해 해석 및 적용된다.

- 서버가 아닌 웹 브라우저에서 해석되어 화면에 적용되기 때문에 웹 서버의 부담을 줄이면서도 다양한 기능을 수행할 수 있다.

<BR>

# 웹 해킹의 이해
<BR>

- 웹 해킹은 웹 사이트의 구조와 동작 원리를 이해하는 것에서 시작한다.

<BR>

## 웹 취약점 스캐너를 통한 정보 수집
<BR>

- 빠른 시간 내에 다양한 접속 시도를 수행할 수 있다는 것이 장점이다.

- 웹 취약점 스캐너를 통해 발견된 취약점은 개별 확인 과정을 거쳐 유효성을 파악하는 과정이 필요하다.

<BR>

## 웹 프록시를 통한 취약점 분석
<BR>

- 웹의 구졸르 파악하거나 취약점을 점검할 때 혹은 웹 해킹을 할 때는 웹 프록시 툴을 사용한다.

- 클라이언트가 웹 서버와 웹 브라우저 간에 전달되는 모든 HTTP 패킷을 웹 프록시를 통해 확인하면서 수정할 수 있다.

<BR>

### 1. 서버에서 클라이언트로 전송되는 패킷 변조
<BR>

- 웹 프록시의 유용한 점은 서버와 클라이언트 사이에 전달되는 과정에서 패킷을 위조/변조할 수 있는 것이다.

- 서버가 클라이언트로 보낸 데이터 변조로 인해 발생하는 위험을 없애려면 서버에서 클라이언트로 전송한 값을 다시 참조하지 말야아 한다.


<br>

### 2. 클라이언트에서 서버로 전송되는 패킷 변조
<br>

- 서버에서 클라이언트로 전송되는 패킷을 변조하는 방법과 클라이언트에서 서버로 전송되는 패킷을 변조하는 방법은 기본적으로 같다.

<br>

## 구글 해킹을 통한 정보 수집
<br>

- 웹 해킹을 하면서 많은 정보를 수집하는 데에는 검색 엔진이 유용하다.

<br>

### 1. 주요 검색 인자
<br>

> site
- 특정 사이트만을 집중적으로 선정해서 검색할 때 유용하다.

<br>

> filetype
- 특정 파일 유형을 검색할 떄 사용한다.

<br>

> intitle
- 디렉터리 리스팅 취약점이 존재하는 사이트를 쉽게 찾을 수 있으므로 정보를 수집할 떄 아주 유용하다.

<br>

### 2. 검색 엔진의 검색을 피하는 방법
<br>

- 웹 서버의 홈디렉터리에 'robots.txt' 파일을 만들어 검색할 수 없게 만드는 것이다.

<br>

# 웹 취약점의 이해
<br>

## 웹의 주요 취약점
<br>

### 1. 명령 삽입 취약점(A1. Injection)
<br>

- SQL, OS, LDAP 등 웹을 통해 명형을 전달하는 어떤 경우에도 적용될 수 있다.

<BR>

> SQL 삽입 공격

: 전송되는 인수에 추가적인 실행을 위한 코드를 넣는 것이다

- 로그인뿐만 아니라 웹에서 사용자의 입력 값을 받아 데이터베이스에 SQL문으로 데이터를 요청하는 모든 곳에 가능하다.

- 인증 뿐만 아니라 경우에 따라서는 매우 다양한 형태의 SQL문을 실행할 수 있다.

<BR>

### 2. 인증 및 세션 관리 취약점(A2. Broken Authentication and Session Management)
<br>

> 취약한 패스워드 설정
- 웹을 비롯해 패스워드를 사용하는 모든 운영체제와 응용 프로그램에 공통적으로 해당한다.

<br>

> 사용자 데이터를 이용한 인증
- 최초 인증 이후에는 인증과 신분 증명 역할을 클라이언트에 넘겼기 때문에 발생한다.

<br>

### 3. XSS 취약점(A3. Cross-Site Scipting)
<br>

        XSS : 공격자가 작성한 스크립트가 다른 사용자에게 전달되는 것이다.


<br>

### 4. 취약한 접근 제어
<br>

: 인증된 사용자가 수행할 수 있는 것에 대한 제한이 제대로 적용되지 않는 것을 의미한다.

<br>

> 디렉터리 탐색

: 웹 브라우저에서 확인 가능한 경로의 상위를 탐색하여 특정 시스템 파일을 다운로드하는 공격 방법이다.

- 자료실에 업로드한 파일을 전용 프로그램으로 내려받는 경우가 있는데. 이때 파일 이름을 필터링하지 않아서 발생하는 취약점이다.

<br>

### 5. 보안 설정 오류(A5. Security Misconfiguration)
<br>

> 디렉터리 리스팅

: 웹 브라우저에서 웹 서버의 특정 디렉터리를 열면 그 디렉터리에 있는 파일과 목록이 모두 나열되는 것이다.

<br>

> 백업 및 임시 파일 존재
- 공격자 입장에서 백업 파일을 발견하면 웹 어플리케이션의 중요한 정보를 획득할 수 있다.

<br>

> 미흡한 주석 관리
- 주석에는 여러 가지 정보가 기록될 수 있다.

- 웹 어플리케이션을 개발하면서 주석에 정보를 기록할 때 주의할 필요가 있다.

<br>

> 파일 업로드 제한 부재
- 클라이언트에서 서버로 임의의 파일을 보냏 수 있다는 것은 웹 서버의 가장 치명적인 취약점이다.

- 웹 해킹의 최종 목표인 이버스 텔넷과 같은 웹 서버 통제권을 얻기 위해 반드시 성공해야 하는 공격이다.

<br>

> 리버스 텔넷

: 웹 해킹으로 시스템 권한을 획득한 후 해당 시스템에 텔넷과 같이 직접 명령을 입력하고 확인할 수 있는 셸을 획득하기 위한 방법이다.

- 방화벽이 있는 시스템을 공격할 때 자주 사용한다.

        텔넷 공격을 막는 방법

        - 파일 업로드를 막아야 한다.

        - exe나 com솨 같은 실행 파일의 업로드도 막아야 한다.

        - 내부에서 외부로의 불필요한 접속도 발화벽으로 막는 것이 좋다.


<br>

### 6. 민감한 데이터 노출(A6. Sensitive Data Exposure)
<br>

- 유명 웹 사이트가 해킹되어 개인 정보가 유출되는 것은 민감한 데이터를 보호하지 않는 것이 주요한 원인이다.

- 민감한 데이터를 보호하여면 데이터의 중요도에 따라 암호화 로직을 사용하고 데이터베이스 테이블 단위에서 암호화를 수행해야 한다.

<br>

### 7. 공격 방어 취약점(A7. Insufficient Attack Protection)
<br>

- 예전에는 대부분의 웹 애플리케이션이 해킹 공격을 탐지, 방지, 대응할 수 있는 기능을 갖추고 있지 않았다.

- 웹 애플리케이션 수준에서 기본적인 입력 유효성 검사를 뛰어넘어 자동으로 탐지, 로깅, 응답 및 공격 시도 차단을 포함하도록 권고하고 있다.

<br>

### 8. CSRF 취약점
<BR>

    CSRF
    
    :  특정 사용자를 대상으로 하지 않고 불특정 다수를 대상으로 로그인된 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위를 하게 만드는 공격이다.

    - 기본적으로 XSS 공격과 매우 유사하다.
- CSRF 공격이 성공하려면 수정/삭제/등록하는 솨정에서 사용자를 구분하는 인숫값이 존재하지 않아야 한다.

<BR>

### 9. 취약점이 있는 컴포넌트 사용(A9. Using Components with Known Vulnerabilities)
<br>

- 보안에 취약한 컴포넌트가 악용되는 경우네는 심각한 데이터 손실이 발생하거나 서버가 장악될 수도 있다.

<br>

### 10. 취약점 API(A10. Underprotected APls)
<br>

- 보안에 취약한 API 사용은 보안 문제를 초래할 수 있다.

<BR>

## 웹의 취약점 보완
<BR>

### 1. 특수문자 필터링
<BR>

- 웹 해킹의 가장 기본적인 형태 중 하나는 인수 조작인데, 이는 예외적인 실행을 유발하기 위해 일반적으로 특수문자를 포함하게 되어있다.

<BR>

### 2. 서버 통제 착용
<BR>

- 파일 업로드 취약점이나 특수문자 필터링을 수행할 때 주의할 점은 자바스크립트와 같은 CSS 기반의 언어로 필터링을 하면 안된다는 것이다.

- CSS 기반의 언어는 췝 프록시를 통해 웹 브라우저에 전달되기 때문에 이 과정에서 변조될 가능성이 있다.

- CSS 기반의 언어로 필터링하는 경우에는 공격자가 필터링 로직만 파악하면 필터링이 쉽게 무력화된다.

<BR>

### 3. 지속적인 세션 관리
<BR>

- 웹 페이지에 대해 일관성 있는 인증 로직을 적용하려면 기업 단위 또는 웹 사이트 단위에서 세션 인증 로직을 표준화하고, 모든 웹 페이지를 개발할 때 표준을 준수하도록 해야 한다.

